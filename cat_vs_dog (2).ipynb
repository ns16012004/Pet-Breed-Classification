{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "VtGFKkkOZTTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install and import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check TensorFlow version\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n"
      ],
      "metadata": {
        "id": "WABUGyYmvhBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Oxford Pets dataset (images + labels only)\n",
        "(ds_train, ds_val), ds_info = tfds.load(\n",
        "    'oxford_iiit_pet',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,  # returns (image, label) pairs\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Number of training samples:\", tf.data.experimental.cardinality(ds_train).numpy())\n",
        "print(\"Number of validation samples:\", tf.data.experimental.cardinality(ds_val).numpy())\n"
      ],
      "metadata": {
        "id": "LwfaE6dIudgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # normalize to [0,1]\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing\n",
        "ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "ds_val = ds_val.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# Shuffle, batch, and prefetch\n",
        "ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "ds_val = ds_val.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "0KlZZB-qudiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n"
      ],
      "metadata": {
        "id": "mOgRxjnNz1NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Oxford-IIIT Pets dataset\n",
        "(ds_train, ds_val), ds_info = tfds.load(\n",
        "    'oxford_iiit_pet',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,  # returns (image, label) pairs\n",
        "    with_info=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "-eJusUlWz1Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))   # Resize to 224x224\n",
        "    image = tf.cast(image, tf.float32) / 255.0              # Normalize to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Train data pipeline\n",
        "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Validation data pipeline\n",
        "ds_val = ds_val.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "8kn_DI9kz1aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained MobileNetV2 base (exclude top)\n",
        "base_model = MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Add custom classification head\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(ds_info.features['label'].num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "o-Ur7Uxgz7Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_val,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "s33UddaW0Ct9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Training Accuracy & Loss"
      ],
      "metadata": {
        "id": "YuZICAYc2RgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fvQTXLC50LIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on Validation Set"
      ],
      "metadata": {
        "id": "RWjdxpq02aKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(ds_val)\n",
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Validation Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "MeaCDz1w2cUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Model\n",
        "# Save in native Keras format\n",
        "model.save('oxford_pet_model.keras')\n",
        "\n"
      ],
      "metadata": {
        "id": "6_d-7LEX2cgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions on New Images"
      ],
      "metadata": {
        "id": "7JSxI0G83lbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "CZh7pO605qDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = Image.open(image_path).resize((224, 224))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(img)\n",
        "    class_idx = np.argmax(prediction)\n",
        "    class_name = ds_info.features['label'].int2str(class_idx)\n",
        "    return class_name\n",
        "\n",
        "# Example: Pass your image path here\n",
        "print(predict_image('/content/photo(cd).jpg'))\n",
        "\n"
      ],
      "metadata": {
        "id": "8MtGn4_W2cie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dog_breeds = [\n",
        "    'affenpinscher', 'afghan_hound', 'airedale', 'akita', 'appenzeller',\n",
        "    'australian_terrier', 'basenji', 'beagle', 'blenheim_spaniel',\n",
        "    'bloodhound', 'border_terrier', 'borzoi', 'boston_bull',\n",
        "    'boxer', 'brabancon_griffon', 'briard', 'chihuahua',\n",
        "    'chow', 'clumber', 'cocker_spaniel', 'collie', 'curly_coated_retriever',\n",
        "    'dandie_dinmont', 'dhole', 'dingo', 'doberman', 'elkhound', 'entlebucher',\n",
        "    'eskimo_dog', 'flat_coated_retriever', 'french_bulldog', 'german_shepherd',\n",
        "    'golden_retriever', 'great_pyrenees', 'great_dane', 'greater_swiss_mountain_dog',\n",
        "    'groenendael', 'ibizan_hound'\n",
        "]  # short list, Oxford-IIIT has 25 dogs, 12 cats\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = Image.open(image_path).resize((224, 224))\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(img)\n",
        "    class_idx = np.argmax(prediction)\n",
        "    class_name = ds_info.features['label'].int2str(class_idx)\n",
        "\n",
        "    # Check if breed is dog or cat\n",
        "    category = \"Dog\" if class_name in dog_breeds else \"Cat\"\n",
        "    return f\"{category} - Breed: {class_name}\"\n",
        "\n",
        "# Example:\n",
        "print(predict_image('/content/photo(cd).jpg'))\n"
      ],
      "metadata": {
        "id": "CzAJRTQO2cl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_image('/content/photo(cd2).jpg'))\n"
      ],
      "metadata": {
        "id": "kelo1X8O6mY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_prediction(image_path):\n",
        "    prediction = predict_image(image_path)\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Prediction: {prediction}\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "show_prediction('/content/photo(cd2).jpg')\n"
      ],
      "metadata": {
        "id": "64JX4ug27auP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --inplace oxford_pet_classifier.ipynb\n"
      ],
      "metadata": {
        "id": "Q-KrU3ka7egx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert --quiet\n",
        "!jupyter nbconvert --ClearMetadataPreprocessor.enabled=True \\\n",
        "--ClearOutputPreprocessor.enabled=True \\\n",
        "--to notebook --output=cleaned_notebook.ipynb \\\n",
        "oxford_pet_classifier.ipynb\n"
      ],
      "metadata": {
        "id": "CVvhlvruGm_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('cleaned_notebook.ipynb')\n"
      ],
      "metadata": {
        "id": "1RRdtRydIZOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "vV2O0t6dIhXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQ2PPP_MIpre"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}